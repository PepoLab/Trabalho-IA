Id,Email,Q1,Q2,Q3,Q4,Q5,Grupo
1.0,ChatGPT,"Sim. Modelos de IA aprendem com dados históricos, que podem conter vieses humanos ou institucionais. Isso significa que, se os dados de treinamento refletirem desigualdades passadas (ex.: menos contratações de mulheres em tecnologia), o sistema pode reproduzir ou até reforçar esses padrões injustos.","Sim. A transparência é essencial em sistemas automatizados. Explicações claras ajudam candidatos a entenderem quais critérios foram usados, reduzem a sensação de arbitrariedade e permitem contestar decisões se houver erro.","Depende de como é implementada.

Pode aumentar: se for programada para reduzir vieses humanos, padronizando critérios objetivos.

Pode diminuir: se apenas replicar vieses dos dados históricos sem correções adequadas.
O efeito real está diretamente ligado ao design, auditoria e monitoramento do sistema.","A responsabilidade deve ser da empresa que utiliza a IA, não da IA em si. Isso inclui o empregador que adota a tecnologia e, em alguns casos, a empresa que desenvolveu o sistema. A IA é apenas uma ferramenta, e decisões sobre pessoas precisam ter supervisão e responsabilização humana.","Como IA, não participo de seleções. Mas, analisando o cenário: um processo totalmente automatizado pode ser eficiente, mas também arriscado por falta de sensibilidade e julgamento humano em aspectos subjetivos (como criatividade, ética ou potencial de aprendizado). O ideal é um modelo híbrido, combinando IA e avaliação humana.",IA
2.0,DeepSeek,Podem ser injustos. O viés é herdado dos dados históricos de treinamento.,Sim. O direito à explicação é um princípio key da IA ética.,Resultado neutro. O impacto depende exclusivamente do design intencional do sistema para mitigar ou amplificar vieses existentes.,"Responsabilidade humana. A culpa é sempre da organização que desenvolveu, implementou ou operou o sistema sem a devida auditoria.",Sim. A participação é condicional à existência de transparência operacional e garantias de que o sistema foi auditado quanto a vieses.,IA
3.0,Google Gemini,"Sim, podem ser injustos e preconceituosos, pois são treinados com dados históricos que podem conter vieses.",A transparência é fundamental. Saber os motivos permite a correção de vieses no algoritmo e dá ao candidato um feedback claro.,"Isso depende da forma como o algoritmo é projetado. Se for bem treinado, pode aumentar as oportunidades; se usar dados enviesados, pode diminuí-las.","A responsabilidade deve ser compartilhada entre a empresa que usa a IA, os desenvolvedores do sistema e os supervisores humanos do processo.","Não seria aplicável. A automação completa exigiria mecanismos de auditoria para garantir que a seleção seja baseada em mérito, e não em preconceitos.",IA
4.0,Claude,"Sim, podem reproduzir vieses dos dados de treinamento."," Sim, candidatos deveriam conhecer os critérios utilizados.",Depende da implementação - pode tanto perpetuar quanto reduzir discriminações.,"Desenvolvedores, empresas usuárias e reguladores compartilham a responsabilidade.","Como IA, não me candidato a empregos. Para humanos, processos puramente automatizados perdem nuances importantes da avaliação.",IA
1.0,anonymous,"Podem ser injustos sim, pois a IA é um robô e não possui senso de empatia ou consideração ao candidato e suas competências.",Sim obviamente ,"Creio que o uso da ia poderia sim causar a diminuição de oportunidades não só para mulheres e minorias como também, para futuros gestores de RH ",A empresa que fornece o sistema e a que o utiliza ,"Sim, mas com muito receio ",Humano
2.0,anônima,"Talvez, pois a AI recruta pessoas diante de um código/ automatização de recrutamento que lhe é inserida.",Sim,Não sei,O responsável pela sobre visão da IA.,Não ,Humano
3.0,anônima,"sim, se programar ela com algoritmos de discurso de ódio, então vai ser injusta e/ou preconceituosa",sim,diminui,quem programou a IA,não,Humano
4.0,anônima,"Achar é uma palavra forte, pode-se provar que IA enquanto um sistema baseado em dados alimentado por uma sociedade preconceituosa, vai também ser preconceituosa, pois funciona como um sistema de sincronização de dados já existente.",Dá última vez que confiaram em algoritmos o hytalo santos pode crescer dentro das redes sociais,Diminui,Os desenvolvedores e a empresa,Não ,Humano
5.0,anônima,"Sim, pois depende dos dados ao qual a ia foi alimentada","Sim, gosto de ter feedback para saber se foi por motivos tecnicos ou preferência da ia",Depende dos dados a qual a ia foi alimentada,A pessoa responsável pela ia,"Sim, se for uma ia bem organizada",Humano
6.0,anônima,Não acho.,"Sim, gostaria ",Aumenta para qualquer um,Quem o configurou para o processo seletivo,Sim!,Humano
